{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1º Etapa\n",
    "\n",
    "Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.29940251144353242</th>\n",
       "      <th>-1.2266241875260637</th>\n",
       "      <th>1.4984250500215328</th>\n",
       "      <th>-1.1761503610375272</th>\n",
       "      <th>5.2898525545597037</th>\n",
       "      <th>0.20829711393323402</th>\n",
       "      <th>2.4044983672405826</th>\n",
       "      <th>1.5945062220589785</th>\n",
       "      <th>-0.051608163273514231</th>\n",
       "      <th>0.66323431039687908</th>\n",
       "      <th>...</th>\n",
       "      <th>-0.85046544625016463</th>\n",
       "      <th>-0.62298999638261954</th>\n",
       "      <th>-1.8330573433160038</th>\n",
       "      <th>0.29302438506869571</th>\n",
       "      <th>3.5526813410266507</th>\n",
       "      <th>0.71761099417552265</th>\n",
       "      <th>3.3059719748508889</th>\n",
       "      <th>-2.7155588147154619</th>\n",
       "      <th>-2.6824085866346223</th>\n",
       "      <th>0.10105047232890663</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819750</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604501</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513906</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.773247</td>\n",
       "      <td>-0.123227</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>-0.210266</td>\n",
       "      <td>10.377793</td>\n",
       "      <td>0.526604</td>\n",
       "      <td>-2.751616</td>\n",
       "      <td>0.315541</td>\n",
       "      <td>0.608603</td>\n",
       "      <td>-0.043421</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.487714</td>\n",
       "      <td>0.792790</td>\n",
       "      <td>-0.540711</td>\n",
       "      <td>0.114115</td>\n",
       "      <td>-0.277477</td>\n",
       "      <td>-0.896411</td>\n",
       "      <td>-2.805207</td>\n",
       "      <td>0.469162</td>\n",
       "      <td>3.614157</td>\n",
       "      <td>0.081689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-0.310429</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>-0.952245</td>\n",
       "      <td>0.768850</td>\n",
       "      <td>1.877520</td>\n",
       "      <td>1.320646</td>\n",
       "      <td>1.944609</td>\n",
       "      <td>1.191420</td>\n",
       "      <td>-0.127724</td>\n",
       "      <td>0.070937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.600411</td>\n",
       "      <td>-0.383792</td>\n",
       "      <td>0.745596</td>\n",
       "      <td>-0.698598</td>\n",
       "      <td>-2.729937</td>\n",
       "      <td>-0.431535</td>\n",
       "      <td>0.372873</td>\n",
       "      <td>1.019092</td>\n",
       "      <td>-2.672811</td>\n",
       "      <td>-0.295141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-1.853879</td>\n",
       "      <td>0.246726</td>\n",
       "      <td>0.459921</td>\n",
       "      <td>-2.074267</td>\n",
       "      <td>7.599220</td>\n",
       "      <td>-0.138355</td>\n",
       "      <td>-4.501900</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>-1.590533</td>\n",
       "      <td>-1.112949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361736</td>\n",
       "      <td>0.240052</td>\n",
       "      <td>-0.856196</td>\n",
       "      <td>-0.072481</td>\n",
       "      <td>-2.935896</td>\n",
       "      <td>0.582411</td>\n",
       "      <td>-2.613407</td>\n",
       "      <td>0.036687</td>\n",
       "      <td>2.809310</td>\n",
       "      <td>4.412567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.912748</td>\n",
       "      <td>-1.734039</td>\n",
       "      <td>-1.047035</td>\n",
       "      <td>0.217573</td>\n",
       "      <td>13.457812</td>\n",
       "      <td>0.162771</td>\n",
       "      <td>-2.250521</td>\n",
       "      <td>2.216161</td>\n",
       "      <td>-0.378326</td>\n",
       "      <td>0.642114</td>\n",
       "      <td>...</td>\n",
       "      <td>1.195896</td>\n",
       "      <td>-1.073806</td>\n",
       "      <td>-2.754369</td>\n",
       "      <td>1.814864</td>\n",
       "      <td>-4.190105</td>\n",
       "      <td>-1.116441</td>\n",
       "      <td>-2.100125</td>\n",
       "      <td>0.061513</td>\n",
       "      <td>0.895536</td>\n",
       "      <td>0.813686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2.439780</td>\n",
       "      <td>-0.735511</td>\n",
       "      <td>-0.902426</td>\n",
       "      <td>1.365036</td>\n",
       "      <td>-10.430299</td>\n",
       "      <td>-0.856859</td>\n",
       "      <td>2.686474</td>\n",
       "      <td>0.292035</td>\n",
       "      <td>0.585388</td>\n",
       "      <td>-0.876965</td>\n",
       "      <td>...</td>\n",
       "      <td>2.262326</td>\n",
       "      <td>-0.039488</td>\n",
       "      <td>0.773876</td>\n",
       "      <td>-0.916066</td>\n",
       "      <td>2.604827</td>\n",
       "      <td>-0.649874</td>\n",
       "      <td>-3.423674</td>\n",
       "      <td>0.229748</td>\n",
       "      <td>-2.311088</td>\n",
       "      <td>-3.422217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.228994</td>\n",
       "      <td>-0.085453</td>\n",
       "      <td>0.876582</td>\n",
       "      <td>1.057401</td>\n",
       "      <td>-1.404015</td>\n",
       "      <td>-1.091965</td>\n",
       "      <td>0.639176</td>\n",
       "      <td>0.701332</td>\n",
       "      <td>-0.906577</td>\n",
       "      <td>-0.390940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471415</td>\n",
       "      <td>1.024757</td>\n",
       "      <td>-1.796571</td>\n",
       "      <td>0.603161</td>\n",
       "      <td>0.862705</td>\n",
       "      <td>0.747234</td>\n",
       "      <td>3.275681</td>\n",
       "      <td>0.400372</td>\n",
       "      <td>-3.431031</td>\n",
       "      <td>2.370080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.29940251144353242  -1.2266241875260637  1.4984250500215328  \\\n",
       "0              -1.174176             0.332157            0.949919   \n",
       "1               1.192222            -0.414371            0.067054   \n",
       "2               1.573270            -0.580318           -0.866332   \n",
       "3              -0.613071            -0.644204            1.112558   \n",
       "4              -0.773247            -0.123227            0.047423   \n",
       "..                   ...                  ...                 ...   \n",
       "994            -0.310429             0.826811           -0.952245   \n",
       "995            -1.853879             0.246726            0.459921   \n",
       "996             0.912748            -1.734039           -1.047035   \n",
       "997             2.439780            -0.735511           -0.902426   \n",
       "998             0.228994            -0.085453            0.876582   \n",
       "\n",
       "     -1.1761503610375272  5.2898525545597037  0.20829711393323402  \\\n",
       "0              -1.285328            2.199061            -0.151268   \n",
       "1              -2.233568            3.658881             0.089007   \n",
       "2              -0.603812            3.125716             0.870321   \n",
       "3              -0.032397            3.490142            -0.011935   \n",
       "4              -0.210266           10.377793             0.526604   \n",
       "..                   ...                 ...                  ...   \n",
       "994             0.768850            1.877520             1.320646   \n",
       "995            -2.074267            7.599220            -0.138355   \n",
       "996             0.217573           13.457812             0.162771   \n",
       "997             1.365036          -10.430299            -0.856859   \n",
       "998             1.057401           -1.404015            -1.091965   \n",
       "\n",
       "     2.4044983672405826  1.5945062220589785  -0.051608163273514231  \\\n",
       "0             -0.427039            2.619246              -0.765884   \n",
       "1              0.203439           -4.219054              -1.184919   \n",
       "2             -0.161992            4.499666               1.038741   \n",
       "3              1.443521           -4.290282              -1.761308   \n",
       "4             -2.751616            0.315541               0.608603   \n",
       "..                  ...                 ...                    ...   \n",
       "994            1.944609            1.191420              -0.127724   \n",
       "995           -4.501900            0.630634              -1.590533   \n",
       "996           -2.250521            2.216161              -0.378326   \n",
       "997            2.686474            0.292035               0.585388   \n",
       "998            0.639176            0.701332              -0.906577   \n",
       "\n",
       "     0.66323431039687908  ...  -0.85046544625016463  -0.62298999638261954  \\\n",
       "0              -0.093780  ...             -0.819750              0.012037   \n",
       "1              -1.240310  ...             -0.604501              0.750054   \n",
       "2              -1.092716  ...              1.022959              1.275598   \n",
       "3               0.807652  ...              0.513906             -1.803473   \n",
       "4              -0.043421  ...             -1.487714              0.792790   \n",
       "..                   ...  ...                   ...                   ...   \n",
       "994             0.070937  ...             -0.600411             -0.383792   \n",
       "995            -1.112949  ...              0.361736              0.240052   \n",
       "996             0.642114  ...              1.195896             -1.073806   \n",
       "997            -0.876965  ...              2.262326             -0.039488   \n",
       "998            -0.390940  ...              0.471415              1.024757   \n",
       "\n",
       "     -1.8330573433160038  0.29302438506869571  3.5526813410266507  \\\n",
       "0               2.038836             0.468579           -0.517657   \n",
       "1              -3.360521             0.856988           -2.751451   \n",
       "2              -3.480110            -1.065252            2.153133   \n",
       "3               0.518579            -0.205029           -4.744566   \n",
       "4              -0.540711             0.114115           -0.277477   \n",
       "..                   ...                  ...                 ...   \n",
       "994             0.745596            -0.698598           -2.729937   \n",
       "995            -0.856196            -0.072481           -2.935896   \n",
       "996            -2.754369             1.814864           -4.190105   \n",
       "997             0.773876            -0.916066            2.604827   \n",
       "998            -1.796571             0.603161            0.862705   \n",
       "\n",
       "     0.71761099417552265  3.3059719748508889  -2.7155588147154619  \\\n",
       "0               0.422326            0.803699             1.213219   \n",
       "1              -1.582735            1.672246             0.656438   \n",
       "2               1.563539            2.767117             0.215748   \n",
       "3              -1.520015            1.830651             0.870772   \n",
       "4              -0.896411           -2.805207             0.469162   \n",
       "..                   ...                 ...                  ...   \n",
       "994            -0.431535            0.372873             1.019092   \n",
       "995             0.582411           -2.613407             0.036687   \n",
       "996            -1.116441           -2.100125             0.061513   \n",
       "997            -0.649874           -3.423674             0.229748   \n",
       "998             0.747234            3.275681             0.400372   \n",
       "\n",
       "     -2.6824085866346223  0.10105047232890663  \n",
       "0               1.382932            -1.817761  \n",
       "1              -0.932473             2.987436  \n",
       "2               0.619645             1.883397  \n",
       "3              -1.894609             0.408332  \n",
       "4               3.614157             0.081689  \n",
       "..                   ...                  ...  \n",
       "994            -2.672811            -0.295141  \n",
       "995             2.809310             4.412567  \n",
       "996             0.895536             0.813686  \n",
       "997            -2.311088            -3.422217  \n",
       "998            -3.431031             2.370080  \n",
       "\n",
       "[999 rows x 40 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_train = pd.read_csv('data-science-london-scikit-learn/train.csv')\n",
    "classe = pd.read_csv('data-science-london-scikit-learn/trainLabels.csv')\n",
    "base_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2º Etapa\n",
    "Como podemos ver, essa base de dado precisa de alguns ajustes, a mudança do cabeçalho como também escalonar os valores das celulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X32</th>\n",
       "      <th>X33</th>\n",
       "      <th>X34</th>\n",
       "      <th>X35</th>\n",
       "      <th>X36</th>\n",
       "      <th>X37</th>\n",
       "      <th>X38</th>\n",
       "      <th>X39</th>\n",
       "      <th>X40</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.773247</td>\n",
       "      <td>-0.123227</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>-0.210266</td>\n",
       "      <td>10.377793</td>\n",
       "      <td>0.526604</td>\n",
       "      <td>-2.751616</td>\n",
       "      <td>0.315541</td>\n",
       "      <td>0.608603</td>\n",
       "      <td>-0.043421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792790</td>\n",
       "      <td>-0.540711</td>\n",
       "      <td>0.114115</td>\n",
       "      <td>-0.277477</td>\n",
       "      <td>-0.896411</td>\n",
       "      <td>-2.805207</td>\n",
       "      <td>0.469162</td>\n",
       "      <td>3.614157</td>\n",
       "      <td>0.081689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-0.310429</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>-0.952245</td>\n",
       "      <td>0.768850</td>\n",
       "      <td>1.877520</td>\n",
       "      <td>1.320646</td>\n",
       "      <td>1.944609</td>\n",
       "      <td>1.191420</td>\n",
       "      <td>-0.127724</td>\n",
       "      <td>0.070937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.383792</td>\n",
       "      <td>0.745596</td>\n",
       "      <td>-0.698598</td>\n",
       "      <td>-2.729937</td>\n",
       "      <td>-0.431535</td>\n",
       "      <td>0.372873</td>\n",
       "      <td>1.019092</td>\n",
       "      <td>-2.672811</td>\n",
       "      <td>-0.295141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-1.853879</td>\n",
       "      <td>0.246726</td>\n",
       "      <td>0.459921</td>\n",
       "      <td>-2.074267</td>\n",
       "      <td>7.599220</td>\n",
       "      <td>-0.138355</td>\n",
       "      <td>-4.501900</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>-1.590533</td>\n",
       "      <td>-1.112949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240052</td>\n",
       "      <td>-0.856196</td>\n",
       "      <td>-0.072481</td>\n",
       "      <td>-2.935896</td>\n",
       "      <td>0.582411</td>\n",
       "      <td>-2.613407</td>\n",
       "      <td>0.036687</td>\n",
       "      <td>2.809310</td>\n",
       "      <td>4.412567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.912748</td>\n",
       "      <td>-1.734039</td>\n",
       "      <td>-1.047035</td>\n",
       "      <td>0.217573</td>\n",
       "      <td>13.457812</td>\n",
       "      <td>0.162771</td>\n",
       "      <td>-2.250521</td>\n",
       "      <td>2.216161</td>\n",
       "      <td>-0.378326</td>\n",
       "      <td>0.642114</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.073806</td>\n",
       "      <td>-2.754369</td>\n",
       "      <td>1.814864</td>\n",
       "      <td>-4.190105</td>\n",
       "      <td>-1.116441</td>\n",
       "      <td>-2.100125</td>\n",
       "      <td>0.061513</td>\n",
       "      <td>0.895536</td>\n",
       "      <td>0.813686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2.439780</td>\n",
       "      <td>-0.735511</td>\n",
       "      <td>-0.902426</td>\n",
       "      <td>1.365036</td>\n",
       "      <td>-10.430299</td>\n",
       "      <td>-0.856859</td>\n",
       "      <td>2.686474</td>\n",
       "      <td>0.292035</td>\n",
       "      <td>0.585388</td>\n",
       "      <td>-0.876965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039488</td>\n",
       "      <td>0.773876</td>\n",
       "      <td>-0.916066</td>\n",
       "      <td>2.604827</td>\n",
       "      <td>-0.649874</td>\n",
       "      <td>-3.423674</td>\n",
       "      <td>0.229748</td>\n",
       "      <td>-2.311088</td>\n",
       "      <td>-3.422217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.228994</td>\n",
       "      <td>-0.085453</td>\n",
       "      <td>0.876582</td>\n",
       "      <td>1.057401</td>\n",
       "      <td>-1.404015</td>\n",
       "      <td>-1.091965</td>\n",
       "      <td>0.639176</td>\n",
       "      <td>0.701332</td>\n",
       "      <td>-0.906577</td>\n",
       "      <td>-0.390940</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024757</td>\n",
       "      <td>-1.796571</td>\n",
       "      <td>0.603161</td>\n",
       "      <td>0.862705</td>\n",
       "      <td>0.747234</td>\n",
       "      <td>3.275681</td>\n",
       "      <td>0.400372</td>\n",
       "      <td>-3.431031</td>\n",
       "      <td>2.370080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2        X3        X4         X5        X6        X7  \\\n",
       "0   -1.174176  0.332157  0.949919 -1.285328   2.199061 -0.151268 -0.427039   \n",
       "1    1.192222 -0.414371  0.067054 -2.233568   3.658881  0.089007  0.203439   \n",
       "2    1.573270 -0.580318 -0.866332 -0.603812   3.125716  0.870321 -0.161992   \n",
       "3   -0.613071 -0.644204  1.112558 -0.032397   3.490142 -0.011935  1.443521   \n",
       "4   -0.773247 -0.123227  0.047423 -0.210266  10.377793  0.526604 -2.751616   \n",
       "..        ...       ...       ...       ...        ...       ...       ...   \n",
       "994 -0.310429  0.826811 -0.952245  0.768850   1.877520  1.320646  1.944609   \n",
       "995 -1.853879  0.246726  0.459921 -2.074267   7.599220 -0.138355 -4.501900   \n",
       "996  0.912748 -1.734039 -1.047035  0.217573  13.457812  0.162771 -2.250521   \n",
       "997  2.439780 -0.735511 -0.902426  1.365036 -10.430299 -0.856859  2.686474   \n",
       "998  0.228994 -0.085453  0.876582  1.057401  -1.404015 -1.091965  0.639176   \n",
       "\n",
       "           X8        X9       X10  ...       X32       X33       X34  \\\n",
       "0    2.619246 -0.765884 -0.093780  ...  0.012037  2.038836  0.468579   \n",
       "1   -4.219054 -1.184919 -1.240310  ...  0.750054 -3.360521  0.856988   \n",
       "2    4.499666  1.038741 -1.092716  ...  1.275598 -3.480110 -1.065252   \n",
       "3   -4.290282 -1.761308  0.807652  ... -1.803473  0.518579 -0.205029   \n",
       "4    0.315541  0.608603 -0.043421  ...  0.792790 -0.540711  0.114115   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "994  1.191420 -0.127724  0.070937  ... -0.383792  0.745596 -0.698598   \n",
       "995  0.630634 -1.590533 -1.112949  ...  0.240052 -0.856196 -0.072481   \n",
       "996  2.216161 -0.378326  0.642114  ... -1.073806 -2.754369  1.814864   \n",
       "997  0.292035  0.585388 -0.876965  ... -0.039488  0.773876 -0.916066   \n",
       "998  0.701332 -0.906577 -0.390940  ...  1.024757 -1.796571  0.603161   \n",
       "\n",
       "          X35       X36       X37       X38       X39       X40 classes  \n",
       "0   -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761       0  \n",
       "1   -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436       0  \n",
       "2    2.153133  1.563539  2.767117  0.215748  0.619645  1.883397       1  \n",
       "3   -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332       0  \n",
       "4   -0.277477 -0.896411 -2.805207  0.469162  3.614157  0.081689       1  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "994 -2.729937 -0.431535  0.372873  1.019092 -2.672811 -0.295141       0  \n",
       "995 -2.935896  0.582411 -2.613407  0.036687  2.809310  4.412567       1  \n",
       "996 -4.190105 -1.116441 -2.100125  0.061513  0.895536  0.813686       1  \n",
       "997  2.604827 -0.649874 -3.423674  0.229748 -2.311088 -3.422217       0  \n",
       "998  0.862705  0.747234  3.275681  0.400372 -3.431031  2.370080       0  \n",
       "\n",
       "[999 rows x 41 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [f\"X{x}\" for x in range(1,41)]\n",
    "predictions\n",
    "\n",
    "data = pd.DataFrame(base_train.values, columns=[predictions])\n",
    "data['classes'] = classe  ## adicionando as classes na base de dados\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_20564\\653738620.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = data.drop('classes', axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_train = data.drop('classes', axis=1)\n",
    "y_train = data['classes']\n",
    "x_train = StandardScaler().fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3º Etapa\n",
    "Agora podemos começar a fazer a criação de alguns modelos de aprendizagem de máquina para posteriormente fazer os testes e encontrar o melhor.\n",
    "Para isso, iremos criar Pipelines para centralizarmos cada modelo de ML para melhor organização e eficiência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_log = Pipeline([\n",
    "    (\"log\", LogisticRegression(solver=\"saga\", max_iter=int(1e4)))\n",
    "])\n",
    "pipe_knn = Pipeline([\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "pipe_rfc = Pipeline([\n",
    "    (\"rfc\", RandomForestClassifier())\n",
    "])\n",
    "pipe_gbc = Pipeline([\n",
    "    (\"gbc\", GradientBoostingClassifier())\n",
    "])\n",
    "pipe_svc = Pipeline([\n",
    "    (\"svc\", SVC())\n",
    "])\n",
    "\n",
    "param_log = {\n",
    "    \"log__C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"log__penalty\": [\"l1\", \"L2\"],\n",
    "}\n",
    "\n",
    "param_knn = {\n",
    "    \"knn__n_neighbors\": np.arange(2,60,2)\n",
    "}\n",
    "\n",
    "param_rfc = {\n",
    "    \"rfc__n_estimators\": [150,200,250],\n",
    "    \"rfc__max_depth\": [3,5]\n",
    "}\n",
    "\n",
    "param_gbc = {\n",
    "    \"gbc__n_estimators\": [150,200,250],\n",
    "    \"gbc__max_depth\" : [3,5]\n",
    "}\n",
    "\n",
    "param_svc = {\n",
    "    \"svc__C\": [1,5,10,15,20],\n",
    "    \"svc__kernel\": [\"linear\",\"poly\", \"rbf\", \"sigmoid\"]\n",
    "}\n",
    "\n",
    "models_name = [\"Logistic Regression\", \"KNNeighbors\", \"Random Forest Classifier\", \"Gradient Boosting Classifier\", \"SVC\"]\n",
    "\n",
    "pipes = [pipe_log, pipe_knn, pipe_knn, pipe_rfc, pipe_gbc, pipe_svc]\n",
    "params = [param_log, param_knn, param_rfc, param_gbc, param_svc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após criarmos, podemos fazer o treinamento e buscar qual tem o melhor accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "50 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'L2' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'L2' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'L2' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'L2' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'L2' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'L2' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.72942857        nan 0.81759184        nan 0.80155102        nan\n",
      " 0.80755102        nan 0.80555102        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'rfc' for estimator Pipeline(steps=[('knn', KNeighborsClassifier())]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 876, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 237, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 69, in _set_params\n    super().set_params(**params)\n  File \"c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 279, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'rfc' for estimator Pipeline(steps=[('knn', KNeighborsClassifier())]). Valid parameters are: ['memory', 'steps', 'verbose'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m x_data_train, x_data_test, y_data_train, y_data_test \u001b[38;5;241m=\u001b[39m train_test_split(x_train,y_train, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, pipe, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(models_name, pipes, params):\n\u001b[1;32m---> 11\u001b[0m     grid \u001b[38;5;241m=\u001b[39m \u001b[43mGridSearchCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     13\u001b[0m     best_models\u001b[38;5;241m.\u001b[39mappend(best_model)\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'rfc' for estimator Pipeline(steps=[('knn', KNeighborsClassifier())]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "\n",
    "best_models = []\n",
    "accuracy_list = []\n",
    "accuracies_dic = {}\n",
    "\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = train_test_split(x_train,y_train, train_size=0.5, random_state=42)\n",
    "\n",
    "for name, pipe, param in zip(models_name, pipes, params):\n",
    "    grid = GridSearchCV(estimator=pipe, param_grid=param, scoring=\"accuracy\", n_jobs=-1, cv=10).fit(x_data_train, y_data_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_models.append(best_model)\n",
    "\n",
    "    accuracies_dic[name] = accuracy_score(y_data_test, best_model.predict(x_data_test))\n",
    "    accuracy_list.append(accuracy_score(y_data_test, best_model.predict(x_data_test)))    \n",
    "\n",
    "accuracies_dic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
